{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rsinghlab/pyaging/blob/main/tutorials/tutorial_cpgptgrimage3.ipynb) [![Open In nbviewer](https://img.shields.io/badge/View%20in-nbviewer-orange)](https://nbviewer.jupyter.org/github/rsinghlab/pyaging/blob/main/tutorials/tutorial_cpgptgrimage3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# ðŸ§¬ âš™ï¸ CpGPT Quick Setup Tutorial âš™ï¸ ðŸ§¬\n",
    "\n",
    "Welcome to the CpGPT Quick Setup Tutorial! ðŸ‘‹ \n",
    "\n",
    "In this notebook, we'll walk you through the fastest way of using CpGPT for your research.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup Environment](#1-setup-environment)\n",
    "2. [Retrieve DNA LLM Embeddings](#2-retrieve-dna-llm-embeddings)\n",
    "3. [Download and Load Model](#3-download-and-load-model)\n",
    "4. [Prepare Data Objects](#4-prepare-data-objects)\n",
    "5. [Run Inference](#5-run-inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "We'll import the necessary Python packages and set up our environment for CpGPT. We'll be using a mix of standard data science libraries and CpGPT-specific modules. We'll also set some important variables that will be used throughout the notebook. Pay attention to these as you may need to adjust them based on your specific setup and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Directory paths\n",
    "DEPENDENCIES_DIR = \"../dependencies\"\n",
    "LLM_DEPENDENCIES_DIR = DEPENDENCIES_DIR + \"/human\"\n",
    "DATA_DIR = \"../data\"\n",
    "PROCESSED_DIR = \"../data/tutorials/processed/quick_setup\"\n",
    "\n",
    "MODEL_NAME = \"cancer\"\n",
    "MODEL_CHECKPOINT_PATH = f\"../dependencies/model/weights/{MODEL_NAME}.ckpt\"\n",
    "MODEL_CONFIG_PATH = f\"../dependencies/model/config/{MODEL_NAME}.yaml\"\n",
    "MODEL_VOCAB_PATH = f\"../dependencies/model/vocab/{MODEL_NAME}.json\"\n",
    "\n",
    "ARROW_DF_PATH = \"../data/cpgcorpus/raw/GSE182215/GPL13534/betas/QCDPB.arrow\"\n",
    "ARROW_DF_FILTERED_PATH = \"../data/tutorials/raw/toy_filtered.arrow\"\n",
    "\n",
    "# The maximum context length to give to the model\n",
    "MAX_INPUT_LENGTH = 20_000 # you might wanna go higher hardware permitting\n",
    "MAX_ATTN_LENGTH = 1_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **âš ï¸ Warning**\n",
    "> \n",
    "> It is recommended to have a GPU for inference as CPU might be slow.\n",
    "> \n",
    "> Reconstructing the methylome for a few hundred samples might take up to one hour on a CPU. âŒ›\n",
    ">\n",
    "> This might be a great exercise in testing your patience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyaging as pya\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# Lightning imports\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "# cpgpt-specific imports\n",
    "from cpgpt.data.components.cpgpt_datasaver import CpGPTDataSaver\n",
    "from cpgpt.data.cpgpt_datamodule import CpGPTDataModule\n",
    "from cpgpt.trainer.cpgpt_trainer import CpGPTTrainer\n",
    "from cpgpt.data.components.dna_llm_embedder import DNALLMEmbedder\n",
    "from cpgpt.data.components.illumina_methylation_prober import IlluminaMethylationProber\n",
    "from cpgpt.infer.cpgpt_inferencer import CpGPTInferencer\n",
    "from cpgpt.model.cpgpt_module import m_to_beta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_everything(RANDOM_SEED, workers=True)\n",
    "try:\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve DNA LLM Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the DNA LLM Embeddings, there are two options:\n",
    "- download the dependencies with all of the sequence embeddings for the CpG sites targeted by the Illumina arrays;\n",
    "- generate from scratch using the DNA LLM directly for loci outside of the ones already available for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m -\u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mInitializing class CpGPTInferencer.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m -\u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing device: cpu.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m -\u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing dependencies directory: ../dependencies\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m -\u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing data directory: ../data\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m -\u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mThere are 19 CpGPT models available such as age, age_cot, average_adultweight, etc.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m -\u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mThere are 2089 GSE datasets available such as GSE100184, GSE100208, GSE100209, etc.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First let's declare the inferencer\n",
    "inferencer = CpGPTInferencer(dependencies_dir=DEPENDENCIES_DIR, data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Download Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The already-processed dependencies contain the sequence embeddings for both human (`s3://cpgpt-lucascamillo-public/dependencies/human`) and several mammalian species (`s3://cpgpt-lucascamillo-public/dependencies/mammalian`). Here, let's use the human as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m -\u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mAll 3 dependency files for human already exist at ../dependencies/human. Skipping download.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inferencer.download_dependencies(species=\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate DNA LLM Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate genomic embeddings for loci outside of the ones already available for download, we can use the `DNALLMEmbedder` class. We need the loci in a list with the following format from ENSEMBL: 'chromosome:position'. Be mindful as this function can take a long time to run dependending on your GPU. For instance, embeddings ~1M genomic loci from the Illumina arrays takes about 12h in an RTX 4090."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LLM_DEPENDENCIES_DIR):\n",
    "\n",
    "    # List CpG genomic locations\n",
    "    example_genomic_locations = ['1:100000', '1:250500', 'X:2031253']\n",
    "\n",
    "    # Declare required class\n",
    "    embedder = DNALLMEmbedder(dependencies_dir=LLM_DEPENDENCIES_DIR)\n",
    "\n",
    "    # Parse the embeddings\n",
    "    embedder.parse_dna_embeddings(\n",
    "        example_genomic_locations,\n",
    "        \"homo_sapiens\",\n",
    "        dna_llm=\"nucleotide-transformer-v2-500m-multi-species\",\n",
    "        dna_context_len=2001,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please first check the model zoo for the available models and their corresponding features on the README.md file. To load any given model, you first need to define the dictionary structure with the hyperparameters and use the `CpGPTInferencer` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Download Checkpoint and Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mModel checkpoint already exists at ../dependencies/model/weights/cancer.ckpt (skipping download).\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mModel config already exists at ../dependencies/model/config/cancer.yaml (skipping download).\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mModel vocabulary already exists at ../dependencies/model/vocab/cancer.json (skipping download).\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mSuccessfully downloaded model 'cancer'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Download the checkpoint and configuration files\n",
    "inferencer.download_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mLoaded CpGPT model config.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mInstantiated CpGPT model from config.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mUsing device: cuda.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mLoading checkpoint from: ../dependencies/model/weights/cancer.ckpt\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mCheckpoint loaded into the model.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load the model configuration\n",
    "config = inferencer.load_cpgpt_config(MODEL_CONFIG_PATH)\n",
    "\n",
    "# Load the model weights\n",
    "model = inferencer.load_cpgpt_model(\n",
    "    config,\n",
    "    model_ckpt_path=MODEL_CHECKPOINT_PATH,\n",
    "    strict_load=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Prepare Data Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform inference, we need to prepare the data objects, which are essentially memory-mapped versions for faster loading. As an example, let's download a toy dataset from the _CpGCorpus_ database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Download and Load Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTInferencer\u001b[0m: \u001b[1mDataset GSE182215 already exists at ../data/cpgcorpus/raw/GSE182215 (skipping download).\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferencer.download_cpgcorpus_dataset(\"GSE182215\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to impute the methylation data for CpGPT -- it simply ignores the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00000029</th>\n",
       "      <th>cg00000108</th>\n",
       "      <th>cg00000109</th>\n",
       "      <th>cg00000165</th>\n",
       "      <th>cg00000236</th>\n",
       "      <th>cg00000289</th>\n",
       "      <th>cg00000292</th>\n",
       "      <th>cg00000321</th>\n",
       "      <th>cg00000363</th>\n",
       "      <th>cg00000622</th>\n",
       "      <th>...</th>\n",
       "      <th>rs7746156</th>\n",
       "      <th>rs798149</th>\n",
       "      <th>rs845016</th>\n",
       "      <th>rs877309</th>\n",
       "      <th>rs9292570</th>\n",
       "      <th>rs9363764</th>\n",
       "      <th>rs939290</th>\n",
       "      <th>rs951295</th>\n",
       "      <th>rs966367</th>\n",
       "      <th>rs9839873</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM5525203</th>\n",
       "      <td>0.324878</td>\n",
       "      <td>0.958127</td>\n",
       "      <td>0.853575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791321</td>\n",
       "      <td>0.249139</td>\n",
       "      <td>0.291044</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.462424</td>\n",
       "      <td>0.100629</td>\n",
       "      <td>0.979795</td>\n",
       "      <td>0.019506</td>\n",
       "      <td>0.947983</td>\n",
       "      <td>0.054746</td>\n",
       "      <td>0.495169</td>\n",
       "      <td>0.675477</td>\n",
       "      <td>0.782523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525204</th>\n",
       "      <td>0.298781</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>0.897159</td>\n",
       "      <td>0.217733</td>\n",
       "      <td>0.874908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828892</td>\n",
       "      <td>0.228412</td>\n",
       "      <td>0.397047</td>\n",
       "      <td>0.013511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0.930166</td>\n",
       "      <td>0.568672</td>\n",
       "      <td>0.493534</td>\n",
       "      <td>0.042713</td>\n",
       "      <td>0.620214</td>\n",
       "      <td>0.511735</td>\n",
       "      <td>0.069878</td>\n",
       "      <td>0.941439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.472385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525206</th>\n",
       "      <td>0.125208</td>\n",
       "      <td>0.961126</td>\n",
       "      <td>0.822223</td>\n",
       "      <td>0.229362</td>\n",
       "      <td>0.861563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877324</td>\n",
       "      <td>0.178019</td>\n",
       "      <td>0.377428</td>\n",
       "      <td>0.017229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550734</td>\n",
       "      <td>0.444213</td>\n",
       "      <td>0.644010</td>\n",
       "      <td>0.563410</td>\n",
       "      <td>0.460727</td>\n",
       "      <td>0.961204</td>\n",
       "      <td>0.051867</td>\n",
       "      <td>0.487339</td>\n",
       "      <td>0.126543</td>\n",
       "      <td>0.899515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525207</th>\n",
       "      <td>0.278861</td>\n",
       "      <td>0.970059</td>\n",
       "      <td>0.929905</td>\n",
       "      <td>0.171255</td>\n",
       "      <td>0.907603</td>\n",
       "      <td>0.820531</td>\n",
       "      <td>0.893471</td>\n",
       "      <td>0.185116</td>\n",
       "      <td>0.377647</td>\n",
       "      <td>0.012591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495878</td>\n",
       "      <td>0.020168</td>\n",
       "      <td>0.483792</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.015444</td>\n",
       "      <td>0.968064</td>\n",
       "      <td>0.551504</td>\n",
       "      <td>0.970979</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>0.764114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 485578 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cg00000029  cg00000108  cg00000109  cg00000165  cg00000236  \\\n",
       "GSM_ID                                                                   \n",
       "GSM5525203    0.324878    0.958127    0.853575         NaN    0.854126   \n",
       "GSM5525204    0.298781    0.939107    0.897159    0.217733    0.874908   \n",
       "GSM5525205         NaN         NaN         NaN         NaN    0.472385   \n",
       "GSM5525206    0.125208    0.961126    0.822223    0.229362    0.861563   \n",
       "GSM5525207    0.278861    0.970059    0.929905    0.171255    0.907603   \n",
       "\n",
       "            cg00000289  cg00000292  cg00000321  cg00000363  cg00000622  ...  \\\n",
       "GSM_ID                                                                  ...   \n",
       "GSM5525203         NaN    0.791321    0.249139    0.291044    0.013388  ...   \n",
       "GSM5525204         NaN    0.828892    0.228412    0.397047    0.013511  ...   \n",
       "GSM5525205         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "GSM5525206         NaN    0.877324    0.178019    0.377428    0.017229  ...   \n",
       "GSM5525207    0.820531    0.893471    0.185116    0.377647    0.012591  ...   \n",
       "\n",
       "            rs7746156  rs798149  rs845016  rs877309  rs9292570  rs9363764  \\\n",
       "GSM_ID                                                                      \n",
       "GSM5525203   0.025733  0.462424  0.100629  0.979795   0.019506   0.947983   \n",
       "GSM5525204   0.978182  0.017012  0.930166  0.568672   0.493534   0.042713   \n",
       "GSM5525205        NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "GSM5525206   0.550734  0.444213  0.644010  0.563410   0.460727   0.961204   \n",
       "GSM5525207   0.495878  0.020168  0.483792  0.021345   0.015444   0.968064   \n",
       "\n",
       "            rs939290  rs951295  rs966367  rs9839873  \n",
       "GSM_ID                                               \n",
       "GSM5525203  0.054746  0.495169  0.675477   0.782523  \n",
       "GSM5525204  0.620214  0.511735  0.069878   0.941439  \n",
       "GSM5525205       NaN       NaN       NaN        NaN  \n",
       "GSM5525206  0.051867  0.487339  0.126543   0.899515  \n",
       "GSM5525207  0.551504  0.970979  0.062037   0.764114  \n",
       "\n",
       "[5 rows x 485578 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather(ARROW_DF_PATH)\n",
    "df.set_index('GSM_ID', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Filter Vocab Features and Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not strictly required, filtering for the features used in finetuning gives you the best chance of achieving good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list\n",
    "vocab = json.load(open(MODEL_VOCAB_PATH, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00000292</th>\n",
       "      <th>cg00002426</th>\n",
       "      <th>cg00003994</th>\n",
       "      <th>cg00005847</th>\n",
       "      <th>cg00008493</th>\n",
       "      <th>cg00009407</th>\n",
       "      <th>cg00011459</th>\n",
       "      <th>cg00012199</th>\n",
       "      <th>cg00012386</th>\n",
       "      <th>cg00012792</th>\n",
       "      <th>...</th>\n",
       "      <th>cg27650175</th>\n",
       "      <th>cg27650434</th>\n",
       "      <th>cg27652350</th>\n",
       "      <th>cg27653134</th>\n",
       "      <th>cg27654142</th>\n",
       "      <th>cg27655905</th>\n",
       "      <th>cg27657283</th>\n",
       "      <th>cg27662379</th>\n",
       "      <th>cg27662877</th>\n",
       "      <th>cg27665659</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM5525203</th>\n",
       "      <td>0.791321</td>\n",
       "      <td>0.905377</td>\n",
       "      <td>0.091164</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>0.951774</td>\n",
       "      <td>0.048334</td>\n",
       "      <td>0.938640</td>\n",
       "      <td>0.035517</td>\n",
       "      <td>0.056877</td>\n",
       "      <td>0.087570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045768</td>\n",
       "      <td>0.072923</td>\n",
       "      <td>0.132974</td>\n",
       "      <td>0.949820</td>\n",
       "      <td>0.065028</td>\n",
       "      <td>0.063921</td>\n",
       "      <td>0.052416</td>\n",
       "      <td>0.077480</td>\n",
       "      <td>0.043270</td>\n",
       "      <td>0.057590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525204</th>\n",
       "      <td>0.828892</td>\n",
       "      <td>0.964620</td>\n",
       "      <td>0.042569</td>\n",
       "      <td>0.125086</td>\n",
       "      <td>0.945982</td>\n",
       "      <td>0.052446</td>\n",
       "      <td>0.951808</td>\n",
       "      <td>0.052040</td>\n",
       "      <td>0.063641</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053291</td>\n",
       "      <td>0.089544</td>\n",
       "      <td>0.130468</td>\n",
       "      <td>0.959386</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.044713</td>\n",
       "      <td>0.069569</td>\n",
       "      <td>0.039361</td>\n",
       "      <td>0.070515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525206</th>\n",
       "      <td>0.877324</td>\n",
       "      <td>0.920315</td>\n",
       "      <td>0.042593</td>\n",
       "      <td>0.201401</td>\n",
       "      <td>0.951397</td>\n",
       "      <td>0.058045</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.051123</td>\n",
       "      <td>0.060039</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.112071</td>\n",
       "      <td>0.096274</td>\n",
       "      <td>0.927876</td>\n",
       "      <td>0.088435</td>\n",
       "      <td>0.056817</td>\n",
       "      <td>0.050824</td>\n",
       "      <td>0.068512</td>\n",
       "      <td>0.070187</td>\n",
       "      <td>0.063018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM5525207</th>\n",
       "      <td>0.893471</td>\n",
       "      <td>0.943485</td>\n",
       "      <td>0.039004</td>\n",
       "      <td>0.139082</td>\n",
       "      <td>0.952827</td>\n",
       "      <td>0.045738</td>\n",
       "      <td>0.950823</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>0.041898</td>\n",
       "      <td>0.082241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047588</td>\n",
       "      <td>0.105776</td>\n",
       "      <td>0.114468</td>\n",
       "      <td>0.940735</td>\n",
       "      <td>0.057654</td>\n",
       "      <td>0.045630</td>\n",
       "      <td>0.036157</td>\n",
       "      <td>0.051430</td>\n",
       "      <td>0.041078</td>\n",
       "      <td>0.082783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19948 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cg00000292  cg00002426  cg00003994  cg00005847  cg00008493  \\\n",
       "GSM_ID                                                                   \n",
       "GSM5525203    0.791321    0.905377    0.091164    0.090651    0.951774   \n",
       "GSM5525204    0.828892    0.964620    0.042569    0.125086    0.945982   \n",
       "GSM5525205         NaN         NaN         NaN         NaN         NaN   \n",
       "GSM5525206    0.877324    0.920315    0.042593    0.201401    0.951397   \n",
       "GSM5525207    0.893471    0.943485    0.039004    0.139082    0.952827   \n",
       "\n",
       "            cg00009407  cg00011459  cg00012199  cg00012386  cg00012792  ...  \\\n",
       "GSM_ID                                                                  ...   \n",
       "GSM5525203    0.048334    0.938640    0.035517    0.056877    0.087570  ...   \n",
       "GSM5525204    0.052446    0.951808    0.052040    0.063641    0.102222  ...   \n",
       "GSM5525205         NaN         NaN         NaN    0.058280         NaN  ...   \n",
       "GSM5525206    0.058045    0.947452    0.051123    0.060039    0.091149  ...   \n",
       "GSM5525207    0.045738    0.950823    0.036847    0.041898    0.082241  ...   \n",
       "\n",
       "            cg27650175  cg27650434  cg27652350  cg27653134  cg27654142  \\\n",
       "GSM_ID                                                                   \n",
       "GSM5525203    0.045768    0.072923    0.132974    0.949820    0.065028   \n",
       "GSM5525204    0.053291    0.089544    0.130468    0.959386    0.066889   \n",
       "GSM5525205         NaN         NaN         NaN         NaN         NaN   \n",
       "GSM5525206    0.046296    0.112071    0.096274    0.927876    0.088435   \n",
       "GSM5525207    0.047588    0.105776    0.114468    0.940735    0.057654   \n",
       "\n",
       "            cg27655905  cg27657283  cg27662379  cg27662877  cg27665659  \n",
       "GSM_ID                                                                  \n",
       "GSM5525203    0.063921    0.052416    0.077480    0.043270    0.057590  \n",
       "GSM5525204    0.055794    0.044713    0.069569    0.039361    0.070515  \n",
       "GSM5525205         NaN         NaN         NaN         NaN         NaN  \n",
       "GSM5525206    0.056817    0.050824    0.068512    0.070187    0.063018  \n",
       "GSM5525207    0.045630    0.036157    0.051430    0.041078    0.082783  \n",
       "\n",
       "[5 rows x 19948 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:, df.columns.isin(vocab['input'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(ARROW_DF_FILTERED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Memory-Map Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform inference, we need to memory-map the data. This is done by using the `CpGPTDataSaver` class. We first need to define the `DNALLMEmbedder` and `IlluminaMethylationProber` classes, which contain the information about the DNA LLM Embeddings and the conversion between Illumina array probes to genomic locations, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mInitializing class DNALLMEmbedder.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mGenome files will be stored under ../dependencies/human/genomes.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mDNA embeddings will be stored under ../dependencies/human/dna_embeddings and subdirectories.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mEnsembl metadata dictionary loaded successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "embedder = DNALLMEmbedder(dependencies_dir=LLM_DEPENDENCIES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mIlluminaMethylationProber\u001b[0m: \u001b[1mInitializing class IlluminaMethylationProber.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mIlluminaMethylationProber\u001b[0m: \u001b[1mIllumina methylation manifest files will be stored under ../dependencies/human/manifests.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mIlluminaMethylationProber\u001b[0m: \u001b[1mIllumina metadata dictionary loaded successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prober = IlluminaMethylationProber(dependencies_dir=LLM_DEPENDENCIES_DIR, embedder=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mInitializing class CpGPTDataSaver.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mDataset folders will be stored under ../data/tutorials/processed/quick_setup.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mLoaded existing genomic locations.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1mStarting file processing.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataSaver\u001b[0m: \u001b[1m1 files already processed. Skipping those.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define datasaver\n",
    "quick_setup_datasaver = CpGPTDataSaver(data_paths=ARROW_DF_FILTERED_PATH, processed_dir=PROCESSED_DIR)\n",
    "\n",
    "# Process the file\n",
    "quick_setup_datasaver.process_files(prober, embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Declare data module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define two data modules: one for the forward pass and reconstructing the methylation, and another one the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mInitializing class DNALLMEmbedder.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mGenome files will be stored under ../dependencies/human/genomes.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mDNA embeddings will be stored under ../dependencies/human/dna_embeddings and subdirectories.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mEnsembl metadata dictionary loaded successfully\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mInitializing class DNALLMEmbedder.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mGenome files will be stored under ../dependencies/human/genomes.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mDNA embeddings will be stored under ../dependencies/human/dna_embeddings and subdirectories.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mDNALLMEmbedder\u001b[0m: \u001b[1mEnsembl metadata dictionary loaded successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define datamodule\n",
    "quick_setup_datamodule = CpGPTDataModule(\n",
    "    predict_dir=PROCESSED_DIR,\n",
    "    dependencies_dir=LLM_DEPENDENCIES_DIR,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    max_length=MAX_INPUT_LENGTH,\n",
    "    dna_llm=config.data.dna_llm,\n",
    "    dna_context_len=config.data.dna_context_len,\n",
    "    sorting_strategy=config.data.sorting_strategy,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "# Define datamodule\n",
    "quick_setup_datamodule_attn = CpGPTDataModule(\n",
    "    predict_dir=PROCESSED_DIR,\n",
    "    dependencies_dir=LLM_DEPENDENCIES_DIR,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    max_length=MAX_ATTN_LENGTH,\n",
    "    dna_llm=config.data.dna_llm,\n",
    "    dna_context_len=config.data.dna_context_len,\n",
    "    sorting_strategy=config.data.sorting_strategy,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to perform inference with CpGPT. Here, we'll go through the most common ones. \n",
    "\n",
    "Different CUDA versions and GPU architectures may yield slightly different numerical results due to hardware-specific optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Declare Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given all models were trained under mixed precision, we'll use the `precision=\"16-mixed\"` argument. However, if you finetune it using a different precision, you can change that accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = CpGPTTrainer(precision=\"16-mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get Sample Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7053e95c364b41fea56a7ba86aa50639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniforge3/envs/cpgpt/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_sample_embeddings = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"forward\",\n",
    "    return_keys=[\"sample_embedding\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_embedding': tensor([[-0.0580, -0.0656, -0.0079,  ..., -0.0076, -0.1528, -0.0810],\n",
       "         [-0.0750, -0.0756, -0.0059,  ..., -0.0241, -0.1455, -0.0859],\n",
       "         [ 0.0325, -0.0363, -0.1413,  ..., -0.0782, -0.1645, -0.1452],\n",
       "         ...,\n",
       "         [-0.0838, -0.0999, -0.0362,  ...,  0.0130, -0.0523, -0.1371],\n",
       "         [-0.0597, -0.0813, -0.0225,  ...,  0.0113, -0.1043, -0.0967],\n",
       "         [-0.0248, -0.0809, -0.0548,  ...,  0.0250, -0.0796, -0.0924]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_sample_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Predict Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6701aaadf441ac991829def24e9af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_pred_conditions = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"forward\",\n",
    "    return_keys=[\"pred_conditions\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_conditions': tensor([[ 0.3667],\n",
       "         [ 0.0154],\n",
       "         [ 6.9766],\n",
       "         [ 0.4402],\n",
       "         [-0.6748],\n",
       "         [-0.2629],\n",
       "         [-0.7241],\n",
       "         [-2.7090],\n",
       "         [-0.1346],\n",
       "         [-0.4250],\n",
       "         [-0.0770],\n",
       "         [ 0.1849],\n",
       "         [-0.0803],\n",
       "         [ 0.4863],\n",
       "         [ 2.5410],\n",
       "         [-1.4512],\n",
       "         [-3.1914],\n",
       "         [ 3.1328],\n",
       "         [-0.7524],\n",
       "         [-1.4854],\n",
       "         [-1.8594],\n",
       "         [-1.4404],\n",
       "         [-2.0391],\n",
       "         [-1.4297],\n",
       "         [-2.4863],\n",
       "         [-2.0703],\n",
       "         [-2.4922],\n",
       "         [-2.4121],\n",
       "         [-2.3438],\n",
       "         [-1.7637],\n",
       "         [-1.4941],\n",
       "         [-2.4941],\n",
       "         [-0.4998],\n",
       "         [-0.5352],\n",
       "         [-1.9775],\n",
       "         [-3.3359],\n",
       "         [-1.0107],\n",
       "         [-0.5669]], dtype=torch.float16)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_pred_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Reconstruct Methylation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's get some the reconstructed methylation values for some locations of interest based on the Illumina probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cg00000292', 'cg00002426', 'cg00003994', 'cg00005847', 'cg00008493']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random probes for demonstration\n",
    "probes = list(df.columns[0:100])\n",
    "\n",
    "probes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16:28878778', '3:57757815', '7:15686236', '2:176164344', '14:93347430']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert probes to genomic locations\n",
    "genomic_locations = prober.locate_probes(probes, \"homo_sapiens\")\n",
    "\n",
    "genomic_locations[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5295ca43bd854f46874501e6f1d6c4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_pred_meth = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"reconstruct\",\n",
    "    genomic_locations=genomic_locations,\n",
    "    species=\"homo_sapiens\",\n",
    "    return_keys=[\"pred_meth\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be mindful as the reconstructed values are M values, not beta values. Therefore, you need to convert them to beta values using the `m_to_beta` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_meth': tensor([[0.8501, 0.8633, 0.0503,  ..., 0.0348, 0.9292, 0.7095],\n",
       "         [0.8706, 0.8833, 0.0492,  ..., 0.0340, 0.9419, 0.7275],\n",
       "         [0.3799, 0.4067, 0.2776,  ..., 0.3308, 0.4133, 0.2937],\n",
       "         ...,\n",
       "         [0.7925, 0.7881, 0.0529,  ..., 0.0367, 0.9351, 0.7075],\n",
       "         [0.8247, 0.8291, 0.0523,  ..., 0.0337, 0.9351, 0.7031],\n",
       "         [0.6494, 0.4927, 0.0576,  ..., 0.0337, 0.9385, 0.7085]],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_pred_meth[\"pred_meth\"] = m_to_beta(quick_setup_pred_meth[\"pred_meth\"])\n",
    "quick_setup_pred_meth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more powerful way of reconstructing the methylation values is using chain-of-thought. With additional test-time compute, we can let the model \"think harder\" about the problem, which can lead to better performance. However, it also takes considerably longer dependending on the number of thinking steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acc5665c097411682686d6c4e3e1eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_pred_meth_cot = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule,\n",
    "    predict_mode=\"reconstruct\",\n",
    "    genomic_locations=genomic_locations,\n",
    "    species=\"homo_sapiens\",\n",
    "    n_thinking_steps=5,\n",
    "    thinking_step_size=1000,\n",
    "    uncertainty_quantile=0.1,\n",
    "    return_keys=[\"pred_meth\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_meth': tensor([[0.8516, 0.8486, 0.0482,  ..., 0.0344, 0.9248, 0.7080],\n",
       "         [0.8691, 0.8696, 0.0484,  ..., 0.0330, 0.9434, 0.7383],\n",
       "         [0.4485, 0.4104, 0.3074,  ..., 0.3823, 0.3540, 0.2976],\n",
       "         ...,\n",
       "         [0.7856, 0.7690, 0.0512,  ..., 0.0355, 0.9326, 0.6919],\n",
       "         [0.8271, 0.8198, 0.0520,  ..., 0.0332, 0.9331, 0.6934],\n",
       "         [0.6523, 0.4868, 0.0560,  ..., 0.0331, 0.9297, 0.7061]],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_setup_pred_meth_cot[\"pred_meth\"] = m_to_beta(quick_setup_pred_meth_cot[\"pred_meth\"])\n",
    "quick_setup_pred_meth_cot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Analyze Attention Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of memory required to store the attention weights is enormous. Therefore, we only use 1000 features for the demonstration. Also, remember that the the first token is the CLS token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mInitializing class CpGPTDataset.\u001b[0m\n",
      "\u001b[1m\u001b[34mcpgpt\u001b[0m\u001b[1m\u001b[0m: \u001b[36mCpGPTDataset\u001b[0m: \u001b[1mLoaded existing dataset metrics.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9ff4bf0f164c078749d80cd707aaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quick_setup_attn = trainer.predict(\n",
    "    model=model,\n",
    "    datamodule=quick_setup_datamodule_attn,\n",
    "    predict_mode=\"attention\",\n",
    "    aggregate_heads=\"mean\",\n",
    "    layer_index=-1,\n",
    "    return_keys=[\"attention_weights\", \"chroms\", \"positions\", \"mask_na\", \"meth\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_weights': tensor([[[0.0011, 0.0010, 0.0009,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0011, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0121, 0.0115, 0.0097,  ...,    nan,    nan,    nan],\n",
       "          [0.0114, 0.0123, 0.0098,  ...,    nan,    nan,    nan],\n",
       "          [0.0105, 0.0110, 0.0222,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0011, 0.0011,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0011, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]],\n",
       " \n",
       "         [[0.0011, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          [0.0010, 0.0010, 0.0010,  ...,    nan,    nan,    nan],\n",
       "          ...,\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
       "          [   nan,    nan,    nan,  ...,    nan,    nan,    nan]]]),\n",
       " 'meth': tensor([[0.8164, 0.0323, 0.0501,  ...,    nan,    nan,    nan],\n",
       "         [0.9417, 0.0925, 0.0540,  ...,    nan,    nan,    nan],\n",
       "         [0.6220, 0.3588, 0.4511,  ...,    nan,    nan,    nan],\n",
       "         ...,\n",
       "         [0.1128, 0.0809, 0.1357,  ...,    nan,    nan,    nan],\n",
       "         [0.7781, 0.0938, 0.0571,  ...,    nan,    nan,    nan],\n",
       "         [0.0147, 0.6906, 0.6015,  ...,    nan,    nan,    nan]]),\n",
       " 'mask_na': tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ...,  True,  True,  True]]),\n",
       " 'chroms': tensor([[ 2,  2,  2,  ..., -1, -1, -1],\n",
       "         [16, 16, 16,  ..., -1, -1, -1],\n",
       "         [ 0,  0,  0,  ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 2,  2,  2,  ..., -1, -1, -1],\n",
       "         [16, 16, 16,  ..., -1, -1, -1],\n",
       "         [ 7,  7,  7,  ..., -1, -1, -1]], dtype=torch.int32),\n",
       " 'positions': tensor([[  394198,   746800,  2140242,  ...,       -1,       -1,       -1],\n",
       "         [ 1394034,  2756719,  2964113,  ...,       -1,       -1,       -1],\n",
       "         [15410502, 24319359, 24902090,  ...,       -1,       -1,       -1],\n",
       "         ...,\n",
       "         [  451100,   536298,   805725,  ...,       -1,       -1,       -1],\n",
       "         [  625585,  1720432,  4859955,  ...,       -1,       -1,       -1],\n",
       "         [  234647,   276727,   689597,  ...,       -1,       -1,       -1]],\n",
       "        dtype=torch.int32)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "quick_setup_attn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
